{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4310761,"sourceType":"datasetVersion","datasetId":2539169}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Brain Tumor Segmentation","metadata":{}},{"cell_type":"markdown","source":"This model will segment the tumors from MRI Images and output the location of the brain tumor","metadata":{}},{"cell_type":"code","source":"!pip install mlflow-skinny","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:23:18.723196Z","iopub.execute_input":"2026-01-07T17:23:18.723983Z","iopub.status.idle":"2026-01-07T17:23:25.553209Z","shell.execute_reply.started":"2026-01-07T17:23:18.723946Z","shell.execute_reply":"2026-01-07T17:23:25.552529Z"}},"outputs":[{"name":"stdout","text":"Collecting mlflow-skinny\n  Downloading mlflow_skinny-3.8.1-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (8.3.1)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (3.1.1)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny)\n  Downloading databricks_sdk-0.77.0-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (0.119.1)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (3.1.45)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (1.37.0)\nRequirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (1.37.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (1.37.0)\nRequirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (25.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (5.29.5)\nRequirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (2.12.5)\nRequirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (1.1.1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (6.0.3)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (2.32.5)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (4.15.0)\nRequirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny) (0.38.0)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny) (2.38.0)\nRequirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny) (0.48.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny) (4.0.12)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny) (3.23.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny) (0.58b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny) (2025.11.12)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny) (0.16.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny) (5.0.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny) (4.9.1)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny) (4.12.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny) (0.6.1)\nDownloading mlflow_skinny-3.8.1-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading databricks_sdk-0.77.0-py3-none-any.whl (779 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: databricks-sdk, mlflow-skinny\nSuccessfully installed databricks-sdk-0.77.0 mlflow-skinny-3.8.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models, datasets, transforms\nfrom torch.utils.data import DataLoader, random_split, Dataset\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nimport os\nimport mlflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:23:25.554738Z","iopub.execute_input":"2026-01-07T17:23:25.554958Z","iopub.status.idle":"2026-01-07T17:23:35.266959Z","shell.execute_reply.started":"2026-01-07T17:23:25.554932Z","shell.execute_reply":"2026-01-07T17:23:35.266413Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Data Augmentation\nimage_transform = transforms.Compose([\n    transforms.Resize((256,256)),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n])\n\nmask_transform = transforms.Compose([\n    transforms.Resize((256,256), interpolation=Image.NEAREST),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:23:35.267778Z","iopub.execute_input":"2026-01-07T17:23:35.268252Z","iopub.status.idle":"2026-01-07T17:23:35.273950Z","shell.execute_reply.started":"2026-01-07T17:23:35.268225Z","shell.execute_reply":"2026-01-07T17:23:35.273280Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, image_transform=None, mask_transform=None):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.image_transform = image_transform\n        self.mask_transform = mask_transform\n        self.images = sorted(os.listdir(image_dir))\n\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.image_dir, self.images[idx])\n        mask_path = os.path.join(self.mask_dir, self.images[idx])\n\n        image = Image.open(img_path).convert(\"RGB\")\n        mask = Image.open(mask_path).convert(\"L\")\n\n        if self.image_transform:\n            image = self.image_transform(image)\n\n        if self.mask_transform:\n            mask = self.mask_transform(mask)\n\n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:30:14.821980Z","iopub.execute_input":"2026-01-07T17:30:14.822555Z","iopub.status.idle":"2026-01-07T17:30:14.828864Z","shell.execute_reply.started":"2026-01-07T17:30:14.822523Z","shell.execute_reply":"2026-01-07T17:30:14.828057Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"dataset = SegmentationDataset(\n    image_dir = \"/kaggle/input/brain-tumor-segmentation/images\",\n    mask_dir = \"/kaggle/input/brain-tumor-segmentation/masks\",\n    image_transform = image_transform,\n    mask_transform = mask_transform\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:30:17.792731Z","iopub.execute_input":"2026-01-07T17:30:17.793112Z","iopub.status.idle":"2026-01-07T17:30:17.801711Z","shell.execute_reply.started":"2026-01-07T17:30:17.793081Z","shell.execute_reply":"2026-01-07T17:30:17.800991Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"dataset_size = len(dataset)\n\ntrain_size = int(0.70 * dataset_size)\nval_size = int(0.15 * dataset_size)\ntest_size = dataset_size - (train_size + val_size)\n\ntrain_dataset, val_dataset, test_dataset = random_split(\n    dataset,\n    [train_size, val_size, test_size]\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:30:20.166816Z","iopub.execute_input":"2026-01-07T17:30:20.167130Z","iopub.status.idle":"2026-01-07T17:30:20.173647Z","shell.execute_reply.started":"2026-01-07T17:30:20.167102Z","shell.execute_reply":"2026-01-07T17:30:20.172874Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"#Building block of the Double convolution of U net\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.conv(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:30:22.878150Z","iopub.execute_input":"2026-01-07T17:30:22.878475Z","iopub.status.idle":"2026-01-07T17:30:22.883943Z","shell.execute_reply.started":"2026-01-07T17:30:22.878446Z","shell.execute_reply":"2026-01-07T17:30:22.883250Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"## Unet\n\nclass UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n    \n        self.down1 = DoubleConv(3,64)\n        self.pool1 = nn.MaxPool2d(2)\n    \n        self.down2 = DoubleConv(64, 128)\n        self.pool2 = nn.MaxPool2d(2)\n    \n        self.down3 = DoubleConv(128, 256)\n        self.pool3 = nn.MaxPool2d(2)\n    \n        self.down4 = DoubleConv(256, 512)\n        self.pool4 = nn.MaxPool2d(2)\n    \n        self.bottleneck = DoubleConv(512, 1024)\n    \n        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n        self.conv4 = DoubleConv(1024, 512)\n    \n        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n        self.conv3 = DoubleConv(512, 256)\n    \n        self.up2 = nn.ConvTranspose2d(256,128, 2, stride=2)\n        self.conv2 = DoubleConv(256, 128)\n    \n        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.conv1 = DoubleConv(128, 64)\n    \n        self.final = nn.Conv2d(64, 1, kernel_size=1)\n\n    def forward(self,x):\n        c1 = self.down1(x)\n        p1 = self.pool1(c1)\n\n        c2 = self.down2(p1)\n        p2 = self.pool2(c2)\n\n        c3 = self.down3(p2)\n        p3 = self.pool3(c3)\n\n        c4 = self.down4(p3)\n        p4 = self.pool4(c4)\n\n        bn = self.bottleneck(p4)\n\n        u4 = self.up4(bn)\n        u4 = torch.cat([u4, c4], dim=1)\n        u4 = self.conv4(u4)\n\n        u3 = self.up3(u4)\n        u3 = torch.cat([u3, c3], dim=1)\n        u3 = self.conv3(u3)\n\n        u2 = self.up2(u3)\n        u2 = torch.cat([u2, c2], dim=1)\n        u2 = self.conv2(u2)\n\n        u1 = self.up1(u2)\n        u1 = torch.cat([u1, c1], dim=1)\n        u1 = self.conv1(u1)\n\n        return torch.sigmoid(self.final(u1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:37:53.128336Z","iopub.execute_input":"2026-01-07T17:37:53.128730Z","iopub.status.idle":"2026-01-07T17:37:53.138823Z","shell.execute_reply.started":"2026-01-07T17:37:53.128697Z","shell.execute_reply":"2026-01-07T17:37:53.137977Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"## Training\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmlflow.set_tracking_uri(\"file:///kaggle/working/mlruns\")\nmlflow.set_experiment(\"tumor segmentation with UNet\")\n\nparams = {\n    \"epochs\": 50,\n    \"learning_rate\":1e-4,\n    \"batch_size\":8\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:55:29.922611Z","iopub.execute_input":"2026-01-07T17:55:29.923240Z","iopub.status.idle":"2026-01-07T17:55:29.929611Z","shell.execute_reply.started":"2026-01-07T17:55:29.923209Z","shell.execute_reply":"2026-01-07T17:55:29.928989Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"## Accuracy models\n\ndef dice_score(preds, targets, smooth=1e-6):\n    preds = (preds > 0.5).float()\n    intersection = (preds * targets).sum()\n    return (2. * intersection + smooth) / (preds.sum() + targets.sum() + smooth)\n\ndef pixel_accuracy(preds, targets):\n    preds = (preds > 0.5).float()\n    correct = (preds == targets).sum()\n    total = targets.numel()\n    return correct / total\n\ndef iou_score(preds, targets, smooth=1e-6):\n    preds = (preds > 0.5).float()\n    intersection = (preds * targets).sum()\n    union = preds.sum() + targets.sum() - intersection\n    return (intersection + smooth) / (union + smooth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:55:32.941824Z","iopub.execute_input":"2026-01-07T17:55:32.942354Z","iopub.status.idle":"2026-01-07T17:55:32.947551Z","shell.execute_reply.started":"2026-01-07T17:55:32.942325Z","shell.execute_reply":"2026-01-07T17:55:32.946755Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"## Training loop function\n# def train_model(train_loader, val_loader, criterion, optimizer):\n\nwith mlflow.start_run():\n\n    mlflow.log_params(params)\n    \n    model = UNet().to(device)\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n    \n    train_dice, val_dice, train_loss, val_loss = [],[],[],[]\n    best_val_dice = 0.0\n    \n    for epoch in range(params[\"epochs\"]):\n        model.train()\n        running_loss = 0.0\n        running_dice = 0.0\n        num_batches = 0\n    \n        for imgs, masks in train_loader:\n            imgs, masks = imgs.to(device), masks.to(device)\n    \n            optimizer.zero_grad()\n            outputs = model(imgs)\n    \n            #Back propergation\n            loss = criterion(outputs, masks)\n            loss.backward()\n            optimizer.step()\n    \n            running_loss += loss.item()\n            running_dice += dice_score(outputs, masks).item()\n            num_batches += 1\n    \n        epoch_train_loss = running_loss/num_batches\n        epoch_train_dice = running_dice/num_batches\n    \n        train_loss.append(epoch_train_loss)\n        train_dice.append(epoch_train_dice)\n    \n        model.eval()\n        running_loss = 0.0\n        running_dice = 0.0\n        num_batches = 0\n    \n        with torch.no_grad():\n            for imgs, masks in val_loader:\n                imgs, masks = imgs.to(device), masks.to(device)\n                outputs = model(imgs)\n    \n                loss = criterion(outputs, masks)\n                running_loss += loss.item()\n    \n                running_dice += dice_score(outputs, masks).item()\n                num_batches += 1\n    \n        epoch_val_loss = running_loss/num_batches\n        epoch_val_dice = running_dice/num_batches\n    \n        val_loss.append(epoch_val_loss)\n        val_dice.append(epoch_val_dice)\n    \n        ## saving the best model\n        if epoch_val_dice > best_val_dice:\n            best_val_dice = epoch_val_dice\n            torch.save(model.state_dict(),\"best_model.pth\")\n    \n        print(f\"Epoch [{epoch+1}/{params[\"epochs\"]}], Tr dice: {100*epoch_train_dice:.2f}%, Val dice: {100*epoch_val_dice:.2f}%, Best Val Acc: {100*best_val_dice:.2f}%\")\n        mlflow.log_metrics({\n            \"training_loss\":epoch_train_loss,\n            \"training_dice\":epoch_train_dice,\n            \"validation_loss\":epoch_val_loss,\n            \"validation_dice\":epoch_val_dice\n        }, step=epoch)\n    \n    print(\"Training Complete\")\n    mlflow.pytorch.log_model(model, artifact_path=\"model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:56:03.912853Z","iopub.execute_input":"2026-01-07T17:56:03.913409Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/50], Tr dice: 0.17%, Val dice: 0.00%, Best Val Acc: 0.00%\nEpoch [2/50], Tr dice: 0.13%, Val dice: 0.01%, Best Val Acc: 0.01%\nEpoch [3/50], Tr dice: 11.34%, Val dice: 17.46%, Best Val Acc: 17.46%\nEpoch [4/50], Tr dice: 28.20%, Val dice: 31.62%, Best Val Acc: 31.62%\nEpoch [5/50], Tr dice: 38.70%, Val dice: 49.94%, Best Val Acc: 49.94%\nEpoch [6/50], Tr dice: 46.95%, Val dice: 54.70%, Best Val Acc: 54.70%\nEpoch [7/50], Tr dice: 52.22%, Val dice: 60.11%, Best Val Acc: 60.11%\nEpoch [8/50], Tr dice: 57.61%, Val dice: 59.53%, Best Val Acc: 60.11%\nEpoch [9/50], Tr dice: 60.00%, Val dice: 65.19%, Best Val Acc: 65.19%\nEpoch [10/50], Tr dice: 65.82%, Val dice: 59.56%, Best Val Acc: 65.19%\nEpoch [11/50], Tr dice: 68.64%, Val dice: 65.36%, Best Val Acc: 65.36%\nEpoch [12/50], Tr dice: 71.80%, Val dice: 70.82%, Best Val Acc: 70.82%\nEpoch [13/50], Tr dice: 76.17%, Val dice: 67.87%, Best Val Acc: 70.82%\nEpoch [14/50], Tr dice: 78.36%, Val dice: 74.06%, Best Val Acc: 74.06%\nEpoch [15/50], Tr dice: 79.87%, Val dice: 70.65%, Best Val Acc: 74.06%\nEpoch [16/50], Tr dice: 81.72%, Val dice: 75.35%, Best Val Acc: 75.35%\nEpoch [17/50], Tr dice: 84.13%, Val dice: 73.27%, Best Val Acc: 75.35%\nEpoch [18/50], Tr dice: 85.76%, Val dice: 75.75%, Best Val Acc: 75.75%\nEpoch [19/50], Tr dice: 86.94%, Val dice: 76.94%, Best Val Acc: 76.94%\nEpoch [20/50], Tr dice: 87.95%, Val dice: 77.24%, Best Val Acc: 77.24%\nEpoch [21/50], Tr dice: 89.53%, Val dice: 77.17%, Best Val Acc: 77.24%\nEpoch [22/50], Tr dice: 89.57%, Val dice: 78.94%, Best Val Acc: 78.94%\nEpoch [23/50], Tr dice: 89.98%, Val dice: 79.07%, Best Val Acc: 79.07%\nEpoch [24/50], Tr dice: 91.46%, Val dice: 79.26%, Best Val Acc: 79.26%\nEpoch [25/50], Tr dice: 92.26%, Val dice: 79.42%, Best Val Acc: 79.42%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}